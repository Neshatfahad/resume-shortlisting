# Resume Shortlisting Automation

A Python-based system for automated resume parsing, semantic matching, and shortlisting against job descriptions. This tool leverages transformer models and LLMs for robust, explainable candidate screening.

---

## üìÅ Project Structure

‚îÇ
‚îú‚îÄ‚îÄ resume_folder/ # Store all candidate resumes (PDF)
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_1_Arav.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_2_Vivaan.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_3_Aditya.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_4_Krishna.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_5_Ishaan.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_6_Anaya.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_7_Diya.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_8_Myra.pdf
‚îÇ ‚îú‚îÄ‚îÄ Structured_Resume_9_Ananya.pdf
‚îÇ ‚îî‚îÄ‚îÄ Structured_Resume_10_Kiara.pdf
‚îÇ
‚îú‚îÄ‚îÄ resume/ # Main code and modules
‚îÇ ‚îú‚îÄ‚îÄ resume_shortlister.py
‚îÇ ‚îú‚îÄ‚îÄ jd_parser_agent.py
‚îÇ ‚îú‚îÄ‚îÄ pyproject.toml
‚îÇ ‚îú‚îÄ‚îÄ .env
‚îÇ ‚îú‚îÄ‚îÄ .python-version
‚îÇ ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ spacyenv/ # (env, optional)
‚îÇ
‚îú‚îÄ‚îÄ pycache/ # (auto-generated)
‚îÇ
‚îî‚îÄ‚îÄ resume_results_*.xlsx # Output Excel files with results

---

## üìù Sample Resumes Provided

The `resume_folder` directory contains a set of sample structured resumes in PDF format. These are used for testing and demonstration purposes.  
When you run the shortlisting script, it will automatically process all PDF files in this folder.

| Filename                          | Candidate Name |
|----------------------------------|----------------|
| Structured_Resume_1_Arav.pdf      | Arav           |
| Structured_Resume_2_Vivaan.pdf    | Vivaan         |
| Structured_Resume_3_Aditya.pdf    | Aditya         |
| Structured_Resume_4_Krishna.pdf   | Krishna        |
| Structured_Resume_5_Ishaan.pdf    | Ishaan         |
| Structured_Resume_6_Anaya.pdf     | Anaya          |
| Structured_Resume_7_Diya.pdf      | Diya           |
| Structured_Resume_8_Myra.pdf      | Myra           |
| Structured_Resume_9_Ananya.pdf    | Ananya         |
| Structured_Resume_10_Kiara.pdf    | Kiara          |

> **Location:** All resumes are located in the `resume_folder` directory at the root of the project.

You can add, remove, or replace PDF files in `resume_folder` as needed.  
The script will automatically process all PDF resumes present in this directory.

---

## ‚öôÔ∏è Setup Instructions

### Clone/Download the Repository

- Place all code inside the `resume` directory.
- Place all candidate resumes (PDFs) in `resume_folder`.

### Install Dependencies

- Ensure **Python 3.8+** is installed.
- Install required packages:

pip install -r requirements.txt
requirements.txt contents:


transformers
torch
pandas
PyMuPDF
groq
python-dotenv
üîê Environment Variables
Create a .env file in the resume directory:


GROQ_API_KEY=your_groq_api_key_here
This key is required for LLM-based parsing and justification.

üöÄ How It Works
Resume Parsing

All PDF resumes in resume_folder are read and text is extracted using PyMuPDF.

Each resume is parsed using a Groq LLM to extract structured fields:
Name, Email, Phone, Skills, Education, Experience, Certifications, Summary.

Job Description (JD) Processing

The job description (JD) is provided as input.

Core required skills are extracted from the JD using regex and heuristics.

Semantic Matching & Scoring

Each resume is scored on:

Relevant Experience: Years of experience weighted by semantic similarity to the JD.

Skills Coverage: Semantic similarity of resume skills/experience to core JD skills.

Education Match: Semantic relevance of education section to JD.

Uses a cross-encoder transformer model (cross-encoder/ms-marco-MiniLM-L-12-v2) for semantic scoring.

LLM Justification

For each resume, a Groq LLM generates a justification/explanation for the match or rejection, strictly based on the JD requirements.

Output

Results are saved as an Excel file (e.g., resume_results_YYYYMMDD_HHMMSS.xlsx).

Each row contains: Resume name, scores, parsed fields, and justification.

üíª Usage
Place all resumes in the resume_folder.

Run the main script:

python resume_shortlister.py
You will be prompted (or can configure) to provide the JD text.

Check the output Excel file for ranked results and explanations.

üóÇÔ∏è Key Files
File	Purpose
resume_shortlister.py	Main script: parsing, scoring, shortlisting, justification
jd_parser_agent.py	JD parsing and core skill extraction logic
.env	Stores API keys securely
pyproject.toml	Python project metadata
README.md	This documentation

‚ö° Customizing the Flow
Skill Extraction:
Edit extract_core_skills_from_jd() in jd_parser_agent.py for custom JD parsing.

Scoring Thresholds:
Adjust interpret_score() and coverage thresholds for stricter or looser shortlisting.

Model Choice:
Change MODEL_NAME in resume_shortlister.py to use different transformer models.

üõ†Ô∏è Troubleshooting
API Key Errors:
Ensure .env is present and GROQ_API_KEY is valid.

PDF Extraction Issues:
Ensure resumes are clear, text-based PDFs (not scanned images).

Performance:
For large batches, consider batching or parallel processing.

üöÄ Extending the Project
Add support for DOCX resumes.

Integrate with HR systems (ATS).

Enhance JD/resume parsing with more advanced LLMs or custom prompts.

üì¨ Contact
For questions or contributions, contact the maintainer or open an issue.

If you want, I can also help generate a ready-to-use `README.md` file you can directly commit. Would you like that?







